{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0f0bc",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc73c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"BUDStrain.csv\", index_col = 0)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "print(train.shape)\n",
    "#train.describe(include = 'all')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c060255",
   "metadata": {},
   "source": [
    "###### No nulls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da15593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fea5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = train.columns.tolist()\n",
    "num_features = train.describe().columns.tolist()\n",
    "cat_features = [feat for feat in all_features if feat not in numerical_features]\n",
    "assert(len(all_features) == len(num_features) + len(cat_features))\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cat_features].nunique().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b07370",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(train[num_features].corr(), annot=True)\n",
    "plt.title(\"Correlation Heatmap between continuous variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb69ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, axes = plt.subplots(4, 4, figsize=(18, 15), sharey=True)\n",
    "fig.suptitle(\"Grades vs Categorical Features\", fontsize=20)\n",
    "\n",
    "sns.boxplot(ax=axes[0, 0], data=train, x='school', y='grade')\n",
    "sns.boxplot(ax=axes[0, 1], data=train, x='higher', y='grade')\n",
    "sns.boxplot(ax=axes[0, 2], data=train, x='internet', y='grade')\n",
    "sns.boxplot(ax=axes[0, 3], data=train, x='nursery', y='grade', order=['yes', 'no'])\n",
    "sns.boxplot(ax=axes[1, 0], data=train, x='activities', y='grade', order=['yes', 'no'])\n",
    "sns.boxplot(ax=axes[1, 1], data=train, x='paid', y='grade', order=['yes', 'no'])\n",
    "sns.boxplot(ax=axes[1, 2], data=train, x='famsup', y='grade')\n",
    "sns.boxplot(ax=axes[1, 3], data=train, x='schoolsup', y='grade')\n",
    "sns.boxplot(ax=axes[2, 0], data=train, x='romantic', y='grade', order=['yes', 'no'])\n",
    "sns.boxplot(ax=axes[2, 1], data=train, x='Pstatus', y='grade')\n",
    "sns.boxplot(ax=axes[2, 2], data=train, x='famsize', y='grade')\n",
    "sns.boxplot(ax=axes[2, 3], data=train, x='address', y='grade')\n",
    "sns.boxplot(ax=axes[3, 0], data=train, x='sex', y='grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8c5ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10), sharey=True)\n",
    "fig.suptitle(\"Grades vs Categorical Features\", fontsize=20)\n",
    "\n",
    "sns.boxplot(ax=axes[0, 0], data=train, x='guardian', y='grade')\n",
    "sns.boxplot(ax=axes[0, 1], data=train, x='reason', y='grade')\n",
    "sns.boxplot(ax=axes[1, 0], data=train, x='Fjob', y='grade')\n",
    "sns.boxplot(ax=axes[1, 1], data=train, x='Mjob', y='grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7fd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, axes = plt.subplots(3, 4, figsize=(18, 12), sharey=True)\n",
    "fig.suptitle(\"Grades vs Numerical Features\", fontsize=20)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        sns.boxplot(ax=axes[i, j], data=train, x=np.array(num_features[:12]).reshape(3,4)[i][j],y='grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b74d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unbalanced datasets\n",
    "plt.figure()\n",
    "fig, axes = plt.subplots(5, 4, figsize=(18, 18), sharey=True)\n",
    "fig.suptitle(\"Categorical Features Counts\", fontsize=20)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        sns.countplot(ax=axes[i, j], data=train, x=np.array(cat_features[:16]).reshape(4,4)[i][j])\n",
    "        for p in axes[i,j].patches:\n",
    "            axes[i,j].annotate('{:.2f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))\n",
    "sns.countplot(ax=axes[4,0], data=train, x=cat_features[-1])\n",
    "for p in axes[4,0].patches:\n",
    "    axes[4,0].annotate('{:.2f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd7c44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Basically also categorical\n",
    "plt.figure()\n",
    "fig, axes = plt.subplots(3, 4, figsize=(18, 12), sharey=True)\n",
    "fig.suptitle(\"Numerical Features Counts\", fontsize=20)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        sns.countplot(ax=axes[i, j], data=train, x=np.array(num_features[:12]).reshape(3,4)[i][j])\n",
    "        for p in axes[i,j].patches:\n",
    "            axes[i,j].annotate('{:.2f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4da01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9df6887c",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c80511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "train = pd.get_dummies(data=train, columns=cat_features)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop('grade', axis=1)\n",
    "y = train['grade']\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102a94e",
   "metadata": {},
   "source": [
    "# ML Algos\n",
    "\n",
    "All categorical variables vs grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907bc80",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lmbdas = np.logspace(-5,5,11)\n",
    "\n",
    "train_accuracy = np.zeros(len(lmbdas))\n",
    "test_accuracy = np.zeros(len(lmbdas))\n",
    "\n",
    "for i, lmbda in enumerate(lmbdas):\n",
    "\n",
    "    lasso_reg = linear_model.Lasso(alpha = lmbda, random_state = 1)   \n",
    "    lasso_reg.fit(train_X, train_y)\n",
    "\n",
    "    # check accuracy\n",
    "    train_accuracy[i] = lasso_reg.score(train_X, train_y)\n",
    "    test_accuracy[i] = lasso_reg.score(val_X, val_y)\n",
    "    \n",
    "plt.semilogx(lmbdas, train_accuracy,'*-b', label='train')\n",
    "plt.semilogx(lmbdas, test_accuracy,'*-r', label='test')\n",
    "plt.title(\"LASSO: Regularization vs R2\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.xlabel(\"Lambdas\")\n",
    "plt.legend()\n",
    "\n",
    "max_acc = max(test_accuracy)\n",
    "max_index = np.argmax(test_accuracy)\n",
    "print(\"Optimal index:\", max_index, \"\\nBest test accuracy:\", max_acc, \"\\nOptimal Lambda:\", lmbdas[max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_opt = linear_model.Lasso(alpha = 0.1, random_state = 1)   \n",
    "lasso_opt.fit(train_X, train_y)\n",
    "val_pred = lasso_opt.predict(val_X)\n",
    "rms = mean_squared_error(val_y, val_pred, squared=False)\n",
    "print('intercept: ', lasso_opt.intercept_)\n",
    "for i in (list(zip(train_X[all_feats], lasso_opt.coef_))):\n",
    "    print(i, sep='\\n')\n",
    "print(f\"RMSE for Lasso w/ lambda=0.1: {rms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001b73f",
   "metadata": {},
   "source": [
    "The variables with the most weights are:\n",
    "\n",
    "`('age', 0.007666)\n",
    "('Medu', 0.09155)\n",
    "('Fedu', 0.31946)\n",
    "('studytime', 0.3659)\n",
    "('failures', -1.2136)\n",
    "('freetime', -0.14597)\n",
    "('Dalc', -0.2047)\n",
    "('Walc', -0.1088)\n",
    "('health', -0.1027)\n",
    "('absences', -0.0156)\n",
    "('school_GP', 0.999)\n",
    "('address_R', -0.139)\n",
    "('Fjob_services', -0.13262)\n",
    "('schoolsup_no', 0.0381)\n",
    "('higher_no', -0.7849)\n",
    "('internet_no', -0.1459)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def sort_tuple(tup): \n",
    "    tup.sort(key = lambda x: x[1]) \n",
    "    return tup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70a413",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ebcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "num_est = np.logspace(1,4,4, dtype=int)\n",
    "\n",
    "for i, num in enumerate(num_est):\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators = num, random_state = 1)\n",
    "    rf.fit(train_X, train_y)\n",
    "    val_pred = rf.predict(val_X)\n",
    "\n",
    "    rmse = mean_squared_error(val_y, val_pred, squared=False)\n",
    "    print(\"\\nRMSE for num_est =\", num, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a82fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Algo is RF with n_est = 10\")\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 1)\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "# Feature Importance\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(all_feats, importances)]\n",
    "\n",
    "f = sort_tuple(feature_importances)\n",
    "for i in f[-5:]:\n",
    "    # top 5 most important features\n",
    "    print(i, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "# Narrowing down parameters for hyperparameter tuning with GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98b9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "# 3 fold CV for run time\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n",
    "rf_random.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab8615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': 200,\n",
    "               'min_samples_split': 5,\n",
    "               'min_samples_leaf': 1,\n",
    "               'max_features': 'sqrt',\n",
    "               'max_depth': 90,\n",
    "               'bootstrap': False}\n",
    "\n",
    "rf = RandomForestRegressor(**best_params, random_state = 1)\n",
    "rf.fit(train_X, train_y)\n",
    "val_pred = rf.predict(val_X)\n",
    "\n",
    "rmse = mean_squared_error(val_y, val_pred, squared=False)\n",
    "print(\"\\nRMSE for num_est =\", num, rmse)\n",
    "\n",
    "# Feature Importance\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(all_feats, importances)]\n",
    "\n",
    "f = sort_tuple(feature_importances)\n",
    "for i in f[-5:]:\n",
    "    # top 5 most important features\n",
    "    print(i, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0550499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [80, 90, 100],\n",
    "    'max_features': [7, 8],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [3, 4, 5, 6, 7],\n",
    "    'n_estimators': [100, 150, 200, 250, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4910b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'bootstrap': False,\n",
    "                'max_depth': 80,\n",
    "                'max_features': 8,\n",
    "                'min_samples_leaf': 1,\n",
    "                'min_samples_split': 6,\n",
    "                'n_estimators': 300}\n",
    "\n",
    "rf = RandomForestRegressor(**best_params, random_state = 1)\n",
    "rf.fit(train_X, train_y)\n",
    "val_pred = rf.predict(val_X)\n",
    "\n",
    "rmse = mean_squared_error(val_y, val_pred, squared=False)\n",
    "print(\"\\nRMSE for num_est =\", num, rmse)\n",
    "\n",
    "# Feature Importance\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(all_feats, importances)]\n",
    "\n",
    "f = sort_tuple(feature_importances)\n",
    "for i in f[-5:]:\n",
    "    # top 5 most important features\n",
    "    print(i, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5dc1e5",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f65611",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = len(all_feats)\n",
    "tf.random.set_seed(1)\n",
    "def create_DNN(unit):\n",
    "    \"\"\"creating DNN architechture \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(unit, input_dim=num_feats, activation='relu'))\n",
    "    model.add(keras.layers.Dense(unit, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d67a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "model=KerasRegressor(build_fn=create_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size':[20, 40, 60, 80, 100], \n",
    "          'epochs':[100, 200, 300, 400],\n",
    "          'unit':[5, 10, 15, 20, 25]\n",
    "           }\n",
    "gs = GridSearchCV(estimator=model, param_grid=params, cv=10)\n",
    "gs_result = gs.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=gs_result.best_params_\n",
    "accuracy=gs_result.best_score_\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0016d4",
   "metadata": {},
   "source": [
    "## DNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d88711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_DNN2(unit):\n",
    "    \"\"\"creating DNN architechture \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(unit, input_dim=num_feats, activation='relu'))\n",
    "    model.add(keras.layers.Dense(unit, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "model=KerasRegressor(build_fn=create_DNN2)\n",
    "\n",
    "params = {'batch_size':[10, 20, 30], \n",
    "          'epochs':[100, 200],\n",
    "          'unit':[30, 50, 70]\n",
    "           }\n",
    "gs = GridSearchCV(estimator=model, param_grid=params, cv=10)\n",
    "gs_result = gs.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb06a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552d7e6",
   "metadata": {},
   "source": [
    "# Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3485650",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"BUDStest.csv\", index_col = 0)\n",
    "test = pd.get_dummies(data=test, columns=cat_features)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e1cbf",
   "metadata": {},
   "source": [
    "#### Random Forest Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'bootstrap': False,\n",
    "                'max_depth': 80,\n",
    "                'max_features': 8,\n",
    "                'min_samples_leaf': 1,\n",
    "                'min_samples_split': 6,\n",
    "                'n_estimators': 300}\n",
    "\n",
    "rf = RandomForestRegressor(**best_params, random_state = 1)\n",
    "rf.fit(train_X, train_y)\n",
    "grade = rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dce98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'ID': test.index, 'grade': grade})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e9860",
   "metadata": {},
   "source": [
    "#### DNN Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'batch_size': 80, 'epochs': 400, 'unit': 25}\n",
    "\n",
    "\n",
    "def create_best_DNN(unit):\n",
    "    \"\"\"creating DNN architechture \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(unit, input_dim=num_feats, activation='relu'))\n",
    "    model.add(keras.layers.Dense(unit, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "DNN = create_best_DNN(25)\n",
    "DNN.fit(train_X, train_y, epochs=400, batch_size=80, verbose=1, validation_data=(val_X, val_y))\n",
    "score = DNN.evaluate(val_X, val_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93434ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = DNN.predict(test)\n",
    "grade = grade.reshape(len(grade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'ID': test.index, 'grade': grade})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066438a",
   "metadata": {},
   "source": [
    "### DNN Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d68b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'batch_size': 20, 'epochs': 100, 'unit': 50}\n",
    "\n",
    "def create_best_DNN2(unit):\n",
    "    \"\"\"creating DNN architechture \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(unit, input_dim=num_feats, activation='relu'))\n",
    "    model.add(keras.layers.Dense(unit, activation='relu'))\n",
    "    model.add(keras.layers.Dense(unit, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "DNN = create_best_DNN2(60)\n",
    "DNN.fit(train_X, train_y, epochs=100, batch_size=20, verbose=1, validation_data=(val_X, val_y))\n",
    "score = DNN.evaluate(val_X, val_y, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3fa84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = DNN.predict(test)\n",
    "grade = grade.reshape(len(grade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e49b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'ID': test.index, 'grade': grade})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd45dff",
   "metadata": {},
   "source": [
    "### For next time\n",
    "\n",
    "Tensorboard and early stopping. Batch Norm? Callback? How to grid search faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e01cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
